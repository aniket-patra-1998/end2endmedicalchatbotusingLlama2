{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anike\\anaconda3\\envs\\mchatbot\\lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "\n",
    "import pinecone\n",
    "import langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_api_key= \"56bd8024-e9fa-4763-af69-1d32202e7e83\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_api_env = \"gcp-starter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract data from pdf\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create chunks\n",
    "def text_split(extracted_data):\n",
    "    chunks = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap =20)\n",
    "    text_chunks = chunks.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = text_split(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of my chunks: 7020\n"
     ]
    }
   ],
   "source": [
    "print(\"len of my chunks:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download embeding model\n",
    "def download_embedding():\n",
    "    embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = download_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "query_result = embedding.embed_query(\"hello world\")\n",
    "print(len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexes': [{'dimension': 384,\n",
       "              'host': 'chatbot-3pgpjm9.svc.gcp-starter.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'chatbot',\n",
       "              'spec': {'pod': {'environment': 'gcp-starter',\n",
       "                               'pod_type': 'starter',\n",
       "                               'pods': 1,\n",
       "                               'replicas': 1,\n",
       "                               'shards': 1}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize pinecone\n",
    "pc = pinecone.Pinecone(api_key = pinecone_api_key)\n",
    "pc.list_indexes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'chatbot'\n",
    "index = pc.Index(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed each chunk and upsert it to index\n",
    "for i,t in zip(range(len(text_chunks)),text_chunks):\n",
    "    query = embedding.embed_query(t.page_content)\n",
    "    index.upsert(\n",
    "        vectors=[\n",
    "            {\n",
    "                \"id\":str(i),\n",
    "                \"values\":query,\n",
    "                \"metadata\":{\"text\":str(text_chunks[i].page_content)}\n",
    "            }\n",
    "        ],\n",
    "\n",
    "        namespace=\"real\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search = Pinecone.from_existing_index(name,embedding)\n",
    "query1 =embedding.embed_query( \"what are allergies\")\n",
    "data = index.query(namespace=\"real\",\n",
    "            vector=query1,\n",
    "            top_k=3,\n",
    "            include_metadata=True,\n",
    "            include_values=False,\n",
    "            filter = {}\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m texts \u001b[38;5;241m=\u001b[39m [match[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatches\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      2\u001b[0m query_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(texts)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "texts = [match['metadata']['text'] for match in data['matches']]\n",
    "query_text = \"\".join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the answer generated is not readabel so we use llm to finetune the answer\n",
    "prompt_template = \"\"\"\n",
    "\n",
    "use the following pieces of information to answe the user's questions.\n",
    "if you dont know the answer just say that you dont know.\n",
    "\n",
    "context = {context}\n",
    "question = {question}\n",
    "\n",
    "only return th ehelpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=prompt_template,input_variables=['context','question'])\n",
    "chain_type_kwargs = {'prompt':prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = CTransformers(model = \"model\\llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                    model_type=\"llama\",\n",
    "                    config = {'max_new_tokens':512,\n",
    "                              'temperature':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = prompt.format(context =query_text, question = \"what are allergies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_response = llm(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
